{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Collection Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fetch data from Kaggle and prepare it for further processes.\n",
        "\n",
        "## Inputs\n",
        "* [https://www.kaggle.com/datasets/jakeshbohaju/brain-tumor](https://www.kaggle.com/datasets/jakeshbohaju/brain-tumor)\n",
        "*   Kaggle JSON file - the authentication token. \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate Dataset: \n",
        "    * input/\n",
        "    * └── Brain Tumor/ (Image files)\n",
        "    * ├── Brain Tumor.csv\n",
        "    * └── bt_dataset_t3.csv\n",
        "\n",
        "## Additional Comments | Insights | Conclusions\n",
        "\n",
        "Brain Tumor Data Set\n",
        "- This dataset includes the Brain MRI image files and two csv files.\n",
        "\n",
        "- The csv files contain brain tumor feature dataset including five first-order features and eight texture features with the target level (in the column Class).\n",
        "\n",
        "    - First Order Features\n",
        "        - Mean\n",
        "        - Variance\n",
        "        - Standard Deviation\n",
        "        - Skewness\n",
        "        - Kurtosis\n",
        "\n",
        "    - Second Order Features\n",
        "        - Contrast\n",
        "        - Energy\n",
        "        - ASM (Angular second moment)\n",
        "        - Entropy\n",
        "        - Homogeneity\n",
        "        - Dissimilarity\n",
        "        - Correlation\n",
        "        - Coarseness \n",
        "\n",
        "- Image column defines image name and Class column defines either the image has tumor or not (1 = Tumor, 0 = Non-Tumor). These two feature are the ones we will take into consideration while classifying the images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -r ../requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Because of the Jupyter notebooks being in a subfolder, we need to change the directory for the code's execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/tom/codeinstitute/brain-tumor-detect/jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/tom/codeinstitute/brain-tumor-detect'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Setup Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle==1.5.12 in ./venv/lib/python3.8/site-packages (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in ./venv/lib/python3.8/site-packages (from kaggle==1.5.12) (1.15.0)\n",
            "Requirement already satisfied: certifi in ./venv/lib/python3.8/site-packages (from kaggle==1.5.12) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil in ./venv/lib/python3.8/site-packages (from kaggle==1.5.12) (2.8.2)\n",
            "Requirement already satisfied: requests in ./venv/lib/python3.8/site-packages (from kaggle==1.5.12) (2.31.0)\n",
            "Requirement already satisfied: tqdm in ./venv/lib/python3.8/site-packages (from kaggle==1.5.12) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in ./venv/lib/python3.8/site-packages (from kaggle==1.5.12) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in ./venv/lib/python3.8/site-packages (from kaggle==1.5.12) (2.1.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in ./venv/lib/python3.8/site-packages (from python-slugify->kaggle==1.5.12) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.8/site-packages (from requests->kaggle==1.5.12) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.8/site-packages (from requests->kaggle==1.5.12) (3.6)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install kaggle==1.5.12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "setup Kaggle details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kaggle json file and directory setup\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "! chmod 600 kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Kaggle download settings and download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading brain-tumor.zip to input\n",
            "100%|██████████████████████████████████████| 14.0M/14.0M [00:01<00:00, 12.7MB/s]\n",
            "100%|██████████████████████████████████████| 14.0M/14.0M [00:01<00:00, 9.78MB/s]\n"
          ]
        }
      ],
      "source": [
        "KAGGLE_DATASET_URL = 'jakeshbohaju/brain-tumor'\n",
        "DESTINATION_FOLDER = 'input/'\n",
        "! kaggle datasets download -d $KAGGLE_DATASET_URL -p $DESTINATION_FOLDER\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unzip the downloaded file, and delete the zip file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Unzip the downloaded file, and delete the zip file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(f'{DESTINATION_FOLDER}/brain-tumor.zip' , 'r') as zip_ref:\n",
        "    zip_ref.extractall(DESTINATION_FOLDER)\n",
        "\n",
        "os.remove(DESTINATION_FOLDER + '/brain-tumor.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Rename directories and files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'Brain Tumor'  'Brain Tumor.csv'   bt_dataset_t3.csv\n"
          ]
        }
      ],
      "source": [
        "! ls input/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "! mv 'input/Brain Tumor.csv' input/brain-tumor.csv\n",
        "! mv input/Brain\\ Tumor/ input/brain-tumor/\n",
        "! mv input/brain-tumor/Brain\\ Tumor/ input/brain-tumor/brain-tumor/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "## Data Cleaning\n",
        "\n",
        "1. Sort the image files into tumor and non-tumor directories\n",
        "2. Remove non image files\n",
        "3. Remove empty directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "brain-tumor\n"
          ]
        }
      ],
      "source": [
        "! ls input/brain-tumor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Change the dir structure of the input folder\n",
        "! mkdir input/mri-brain-tumor/\n",
        "! cp input/brain-tumor/brain-tumor/* input/mri-brain-tumor/\n",
        "! rm -rf input/brain-tumor/ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3762 entries, 0 to 3761\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Image   3762 non-null   object\n",
            " 1   Class   3762 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 58.9+ KB\n"
          ]
        }
      ],
      "source": [
        "# classify images according to the target 'Class'\n",
        "import pandas as pd\n",
        "df = pd.read_csv('input/brain-tumor.csv')\n",
        "\n",
        "# take out Image and Class only into a new data set\n",
        "new_df = df[['Image', 'Class']]\n",
        "new_df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# make new directories mri-tumor and mri-non-tumor in input\n",
        "os.mkdir('input/mri-tumor/')\n",
        "os.mkdir('input/mri-non-tumor/')\n",
        "\n",
        "# move files according to the class\n",
        "for index, row in new_df.iterrows():\n",
        "    image_file = row['Image'] + '.jpg'\n",
        "    image_class = row['Class']\n",
        "    # save the image into the folder according to the class\n",
        "    if image_class == 0:\n",
        "        # save the image into the folder according to the class\n",
        "        shutil.move('input/mri-brain-tumor/'+ image_file, 'input/mri-non-tumor/')\n",
        "    else:\n",
        "        # save the image into the folder according to the class\n",
        "        shutil.move('input/mri-brain-tumor/'+ image_file, 'input/mri-tumor/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove non image files and empty folders\n",
        "! rm input/*.csv\n",
        "! rm -rf input/mri-brain-tumor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['mri-tumor', 'mri-non-tumor']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir('input')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split train validation test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "# code adapted from the CI walkthrough project malaria detector\n",
        "def split_dataset(input_dir, train_set_ratio, validation_set_ratio, test_set_ratio):\n",
        "    if train_set_ratio + validation_set_ratio + test_set_ratio != 1.0:\n",
        "        print(\"train_set_ratio + validation_set_ratio + test_set_ratio should sum to 1.0\")\n",
        "        return\n",
        "    \n",
        "    labels = os.listdir(input_dir)  \n",
        "    if 'test' in labels:\n",
        "        pass\n",
        "    else:\n",
        "        # create train, test and validation folders with classes labels sub-folder\n",
        "        for folder in ['train', 'test', 'validation']:\n",
        "            os.makedirs(os.path.join(input_dir, folder))\n",
        "            for label in labels:\n",
        "                os.makedirs(os.path.join(input_dir, folder, label))\n",
        "\n",
        "        for label in labels:\n",
        "            images = os.listdir(os.path.join(input_dir, label))\n",
        "            random.shuffle(images)\n",
        "            train_set_size = int(len(images) * train_set_ratio)\n",
        "            test_set_size = int(len(images) * test_set_ratio)\n",
        "            validation_set_size = len(images) - train_set_size - test_set_size\n",
        "\n",
        "            for image in images[:train_set_size]:\n",
        "                shutil.move(os.path.join(input_dir, label, image), os.path.join(input_dir, 'train', label))\n",
        "            for image in images[train_set_size:train_set_size + test_set_size]:\n",
        "                shutil.move(os.path.join(input_dir, label, image), os.path.join(input_dir, 'test', label))\n",
        "            for image in images[train_set_size + test_set_size:]:\n",
        "                shutil.move(os.path.join(input_dir, label, image), os.path.join(input_dir, 'validation', label))\n",
        "\n",
        "            os.rmdir(os.path.join(input_dir, label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conventionally,\n",
        "* The training set is divided into a 0.70 ratio of data.\n",
        "* The validation set is divided into a 0.10 ratio of data.\n",
        "* The test set is divided into a 0.20 ratio of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_dataset(input_dir='input', train_set_ratio=0.7, validation_set_ratio=0.1, test_set_ratio=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Data collection and cleaning has finished. You can push the files to the GitHub repository and close this notebook.\n",
        "* Follows [Data Visualization Notebook](./02_data_visualization.ipynb)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
